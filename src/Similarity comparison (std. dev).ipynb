{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'cnn.py', 'Comparing methods for predicting height.ipynb', 'correction factors.py', 'curve fit.py', 'curve_fit2.py', 'dnnetwork.py', 'errors.txt', 'interface copy.py', 'interface.py', 'jd_bst.py', 'jd_bst_2.py', 'kmeans_model.pkl', 'my_model.h5', 'my_model.keras', 'nn2.py', 'nnetwork.py', 'PBarnesI.py', 'random_forest.joblib', 'scaler.joblib', 'shaperec.py', 'Similarity comparison (std. dev).ipynb', 'similarity_comparison.py', 'svk_600_60_dt_men_2018.csv', 'svk_600_60_dt_women_2018.csv', 'svk_height_weight_mens_2008_v2.csv', 'svk_height_weight_womens_2018_v2.csv', 'test.html', 'test_model.py']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import diff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from IPython.display import clear_output\n",
    "import scipy\n",
    "print(os.listdir())\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_12172\\4021082537.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mens = pd.read_csv('svk_height_weight_mens_2008_v2.csv',sep=',', index_col=0).reset_index(drop=True)\n",
    "df_womens = pd.read_csv('svk_height_weight_womens_2018_v2.csv',sep=',', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_id</th>\n",
       "      <th>ATV_8</th>\n",
       "      <th>ATV_9</th>\n",
       "      <th>ATV_10</th>\n",
       "      <th>ATV_11</th>\n",
       "      <th>ATV_12</th>\n",
       "      <th>ATV_13</th>\n",
       "      <th>ATV_14</th>\n",
       "      <th>ATV_15</th>\n",
       "      <th>ATV_16</th>\n",
       "      <th>ATV_17</th>\n",
       "      <th>ATV_18</th>\n",
       "      <th>ATT_8</th>\n",
       "      <th>ATT_9</th>\n",
       "      <th>ATT_10</th>\n",
       "      <th>ATT_11</th>\n",
       "      <th>ATT_12</th>\n",
       "      <th>ATT_13</th>\n",
       "      <th>ATT_14</th>\n",
       "      <th>ATT_15</th>\n",
       "      <th>ATT_16</th>\n",
       "      <th>ATT_17</th>\n",
       "      <th>ATT_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7482</th>\n",
       "      <td>1000332799</td>\n",
       "      <td>1285.000000</td>\n",
       "      <td>1335.000000</td>\n",
       "      <td>1382.500000</td>\n",
       "      <td>1417.5</td>\n",
       "      <td>1465.000000</td>\n",
       "      <td>1527.000000</td>\n",
       "      <td>1617.000000</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1695.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>307.500000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>577.5</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>680.000000</td>\n",
       "      <td>690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>1000315828</td>\n",
       "      <td>1347.916667</td>\n",
       "      <td>1385.833333</td>\n",
       "      <td>1454.916667</td>\n",
       "      <td>1512.0</td>\n",
       "      <td>1553.666667</td>\n",
       "      <td>1656.583333</td>\n",
       "      <td>1743.333333</td>\n",
       "      <td>1782.0</td>\n",
       "      <td>1805.583333</td>\n",
       "      <td>1823.333333</td>\n",
       "      <td>1827.083333</td>\n",
       "      <td>264.166667</td>\n",
       "      <td>314.166667</td>\n",
       "      <td>365.916667</td>\n",
       "      <td>433.166667</td>\n",
       "      <td>464.166667</td>\n",
       "      <td>549.083333</td>\n",
       "      <td>617.166667</td>\n",
       "      <td>631.5</td>\n",
       "      <td>648.583333</td>\n",
       "      <td>657.416667</td>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        child_id        ATV_8        ATV_9       ATV_10  ATV_11       ATV_12  \\\n",
       "7482  1000332799  1285.000000  1335.000000  1382.500000  1417.5  1465.000000   \n",
       "7006  1000315828  1347.916667  1385.833333  1454.916667  1512.0  1553.666667   \n",
       "\n",
       "           ATV_13       ATV_14  ATV_15       ATV_16       ATV_17       ATV_18  \\\n",
       "7482  1527.000000  1617.000000  1675.0  1685.000000  1695.000000  1725.000000   \n",
       "7006  1656.583333  1743.333333  1782.0  1805.583333  1823.333333  1827.083333   \n",
       "\n",
       "           ATT_8       ATT_9      ATT_10      ATT_11      ATT_12      ATT_13  \\\n",
       "7482  280.000000  307.500000  325.000000  370.000000  415.000000  453.000000   \n",
       "7006  264.166667  314.166667  365.916667  433.166667  464.166667  549.083333   \n",
       "\n",
       "          ATT_14  ATT_15      ATT_16      ATT_17  ATT_18  \n",
       "7482  518.000000   577.5  635.000000  680.000000   690.0  \n",
       "7006  617.166667   631.5  648.583333  657.416667   682.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mens.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdf_mens\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mens' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9181"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_womens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "atv_column_names = [x for x in df_mens.columns if 'ATV' in x]\n",
    "df_mens_atv = df_mens[atv_column_names]\n",
    "atv_column_names = [x for x in df_womens.columns if 'ATV' in x]\n",
    "df_womens_atv = df_womens[atv_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mens_atv = df_mens_atv[(df_mens_atv != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_womens_atv = df_womens_atv[(df_womens_atv != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_column_names = [x for x in df_mens.columns if 'ATT' in x]\n",
    "df_mens_att = df_mens[att_column_names]\n",
    "att_column_names = [x for x in df_womens.columns if 'ATT' in x]\n",
    "df_womens_att = df_womens[att_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mens_600m = pd.read_csv('svk_600_60_dt_men_2018.csv',sep=',', index_col=0).reset_index(drop=True)\n",
    "df_womens_600m = pd.read_csv('svk_600_60_dt_women_2018.csv',sep=',', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "att600_column_names = [x for x in df_mens_600m.columns if 'T600' in x]\n",
    "df_mens_att600 = df_mens_600m[att600_column_names]\n",
    "att600_column_names = [x for x in df_womens_600m.columns if 'T600' in x]\n",
    "df_womens_att600 = df_womens_600m[att600_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mens_600m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\James\\OneDrive - Nottingham Trent University\\SHP\\height-forecasting-main\\src\\Similarity comparison (std. dev).ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m atdt_column_names \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df_mens_600m\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mDT\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m x] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_mens_atv \u001b[39m=\u001b[39m df_mens_600m[atdt_column_names]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m atdt_column_names \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df_womens_600m\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mDT\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m x]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mens_600m' is not defined"
     ]
    }
   ],
   "source": [
    "atdt_column_names = [x for x in df_mens_600m.columns if 'DT' in x] \n",
    "df_mens_atv = df_mens_600m[atdt_column_names]\n",
    "atdt_column_names = [x for x in df_womens_600m.columns if 'DT' in x]\n",
    "df_womens_atdt = df_womens_600m[atdt_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ATV_8        ATV_9       ATV_10       ATV_11       ATV_12  \\\n",
      "0     1315.000000  1380.000000  1425.000000  1481.000000  1525.000000   \n",
      "1     1310.000000  1375.000000  1430.000000  1485.000000  1540.000000   \n",
      "2     1290.000000  1365.000000  1393.000000  1437.000000  1495.000000   \n",
      "3     1370.000000  1434.000000  1507.000000  1557.000000  1597.000000   \n",
      "4     1360.000000  1425.000000  1475.000000  1525.000000  1580.000000   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "7572  1249.166667  1298.750000  1345.000000  1405.000000  1468.333333   \n",
      "7573  1331.666667  1378.333333  1413.333333  1446.666667  1495.000000   \n",
      "7574  1325.000000  1365.000000  1425.000000  1485.000000  1570.000000   \n",
      "7575  1245.000000  1304.166667  1354.166667  1406.666667  1488.750000   \n",
      "7576  1335.000000  1401.666667  1461.666667  1518.666667  1580.666667   \n",
      "\n",
      "           ATV_13       ATV_14       ATV_15       ATV_16       ATV_17  \\\n",
      "0     1618.000000  1702.000000  1745.000000  1766.000000  1778.000000   \n",
      "1     1630.000000  1735.000000  1795.000000  1800.000000  1812.000000   \n",
      "2     1560.000000  1680.000000  1770.000000  1814.000000  1828.000000   \n",
      "3     1695.000000  1791.000000  1835.000000  1870.000000  1878.000000   \n",
      "4     1630.000000  1720.000000  1790.000000  1807.000000  1824.000000   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "7572  1567.500000  1653.666667  1697.833333  1740.166667  1742.250000   \n",
      "7573  1547.333333  1621.333333  1703.333333  1760.000000  1783.333333   \n",
      "7574  1680.000000  1733.000000  1790.000000  1790.000000  1801.000000   \n",
      "7575  1591.250000  1662.500000  1690.500000  1696.833333  1706.333333   \n",
      "7576  1647.333333  1728.666667  1699.333333  1686.000000  1702.000000   \n",
      "\n",
      "           ATV_18  \n",
      "0     1775.000000  \n",
      "1     1814.000000  \n",
      "2     1854.000000  \n",
      "3     1895.000000  \n",
      "4     1828.000000  \n",
      "...           ...  \n",
      "7572  1746.250000  \n",
      "7573  1791.666667  \n",
      "7574  1812.000000  \n",
      "7575  1709.166667  \n",
      "7576  1706.000000  \n",
      "\n",
      "[7569 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_mens_atv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we calculate difefrences between years, we need to name the columns right, so we prepare the names here\n",
    "atv_column_names_gradient = []\n",
    "for i in range(8, 18):\n",
    "    atv_column_names_gradient.append('ATV_diff_'+str(i)+'-'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "start_age: 8\n",
      "------------------\n",
      "0\n",
      "age: 10\n",
      "7569\n",
      "181.77552564102564\n",
      "1774.9999999999995\n",
      "42.755256410256834\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [59], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m     predicting_errors\u001b[38;5;241m.\u001b[39mappend(predicting_error)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mprint\u001b[39m(predicting_error)\n\u001b[1;32m---> 63\u001b[0m     z\u001b[38;5;241m=\u001b[39m\u001b[43mz\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#Average predicting error\u001b[39;00m\n\u001b[0;32m     66\u001b[0m average_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmedian(predicting_errors)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "#Height men\n",
    "all_all_errors=[]\n",
    "import numpy as np\n",
    "for start_age in range(8,18):\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    print(col_index_for_start_age)\n",
    "    diffs = np.diff(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_devs=[]\n",
    "    for age in range(10,18):\n",
    "        print('age:', age)\n",
    "        col_index_for_age = age-start_age #first year = 8\n",
    "        remaining_ages_for_difference = 18-age\n",
    "        number_of_similar_rows_to_include_for_predictions = 100\n",
    "        predicting_errors =[]\n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        #print(col_index_for_start_age)\n",
    "        #print(col_index_for_age)\n",
    "        #similarity = cosine_similarity(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]])\n",
    "        similarity = scipy.spatial.distance.cdist(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "        print(len(similarity))\n",
    "        #We iterate through rows\n",
    "        for i in range(len(similarity)):\n",
    "            row = similarity[i]\n",
    "            sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "            \n",
    "           \n",
    "            del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "            #We get rows with simmilar differences\n",
    "            similar_rows = []\n",
    "            for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                similar_rows.append(df_grad.iloc[sorted_indexes[j]])\n",
    "\n",
    "            #Now we need to calculate remaining differences to estimate value at 18\n",
    "            next_diferences = [0]*remaining_ages_for_difference\n",
    "            #print(similar_rows[-1])\n",
    "            #print()\n",
    "            for similar_row in similar_rows:\n",
    "                for k in range(remaining_ages_for_difference):\n",
    "                    next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                    #print(similar_row[-k-1])\n",
    "            next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "            all_next_differences = sum(next_diferences)\n",
    "            current_value = 1449.0\n",
    "\n",
    "            predicted_value = current_value + all_next_differences \n",
    "            print(predicted_value/10)\n",
    "            \n",
    "            actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[-1]]\n",
    "            print(actual_value)\n",
    "            \n",
    "            predicting_error = abs(predicted_value - actual_value)\n",
    "            predicting_errors.append(predicting_error)\n",
    "            print(predicting_error)\n",
    "            z=z\n",
    "\n",
    "        #Average predicting error\n",
    "        average_error = np.median(predicting_errors)\n",
    "        std_error = np.std(predicting_errors)\n",
    "        print('Average error: ' + str(average_error))\n",
    "        print('Std. error: ' + str(std_error))\n",
    "        all_errors.append(average_error)\n",
    "        all_std_devs.append(std_error)\n",
    "    print(all_errors)\n",
    "    print(all_std_devs)\n",
    "    print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "start_age: 8\n",
      "------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [53], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m similar_rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_similar_rows_to_include_for_predictions):\n\u001b[1;32m---> 36\u001b[0m     similar_rows\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdf_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m#Now we need to calculate remaining differences to estimate value at 18\u001b[39;00m\n\u001b[0;32m     39\u001b[0m next_diferences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39mremaining_ages_for_difference\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1522\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[1;32m-> 1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3428\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[1;34m(self, i, axis)\u001b[0m\n\u001b[0;32m   3426\u001b[0m \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[0;32m   3427\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_values, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_values\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 3428\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor_sliced\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3430\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3433\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3434\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_is_copy(\u001b[38;5;28mself\u001b[39m, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   3435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:455\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    453\u001b[0m manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 455\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mSingleBlockManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    457\u001b[0m     data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1736\u001b[0m, in \u001b[0;36mSingleBlockManager.from_array\u001b[1;34m(cls, array, index)\u001b[0m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_array\u001b[39m(\u001b[38;5;28mcls\u001b[39m, array: ArrayLike, index: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SingleBlockManager:\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;124;03m    Constructor for if we have an array that is not yet a Block.\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1736\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[43mnew_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(block, index)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:2053\u001b[0m, in \u001b[0;36mnew_block\u001b[1;34m(values, placement, ndim)\u001b[0m\n\u001b[0;32m   2049\u001b[0m check_ndim(values, placement, ndim)\n\u001b[0;32m   2051\u001b[0m klass \u001b[38;5;241m=\u001b[39m get_block_type(values\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m-> 2053\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_coerce_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m klass(values, ndim\u001b[38;5;241m=\u001b[39mndim, placement\u001b[38;5;241m=\u001b[39mplacement)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1979\u001b[0m, in \u001b[0;36mmaybe_coerce_values\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;66;03m# Caller is responsible for ensuring PandasArray is already extracted.\u001b[39;00m\n\u001b[0;32m   1978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 1979\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mensure_wrapped_if_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1982\u001b[0m         values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\construction.py:443\u001b[0m, in \u001b[0;36mensure_wrapped_if_datetimelike\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;124;03mWrap datetime64 and timedelta64 ndarrays in DatetimeArray/TimedeltaArray.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m:\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatetimeArray\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DatetimeArray\u001b[38;5;241m.\u001b[39m_from_sequence(arr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Height women\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,18):\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_devs=[]\n",
    "    for age in range(start_age,18):\n",
    "        #print(age)\n",
    "        col_index_for_age = age-start_age #first year = 8\n",
    "        remaining_ages_for_difference = 18-age\n",
    "        number_of_similar_rows_to_include_for_predictions = 100\n",
    "        predicting_errors =[]\n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        #print(col_index_for_start_age)\n",
    "        #print(col_index_for_age)\n",
    "        #similarity = cosine_similarity(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]])\n",
    "        similarity = scipy.spatial.distance.cdist(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "\n",
    "        #We iterate through rows\n",
    "        for i in range(len(similarity)):\n",
    "            row = similarity[i]\n",
    "            sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "            del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "            #We get rows with simmilar differences\n",
    "            similar_rows = []\n",
    "            for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                similar_rows.append(df_grad.iloc[sorted_indexes[j]])\n",
    "\n",
    "            #Now we need to calculate remaining differences to estimate value at 18\n",
    "            next_diferences = [0]*remaining_ages_for_difference\n",
    "            #print(similar_rows[-1])\n",
    "            #print()\n",
    "            for similar_row in similar_rows:\n",
    "                for k in range(remaining_ages_for_difference):\n",
    "                    next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                    #print(similar_row[-k-1])\n",
    "            next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "            all_next_differences = sum(next_diferences)\n",
    "            current_value = df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age]]\n",
    "\n",
    "            predicted_value = current_value + all_next_differences\n",
    "            actual_value = df_womens_atv.iloc[i][df_womens_atv.columns[-1]]\n",
    "\n",
    "            predicting_error = abs(predicted_value - actual_value)\n",
    "            predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "        #Average predicting error\n",
    "        average_error = np.median(predicting_errors)\n",
    "        std_error = np.std(predicting_errors)\n",
    "        print('Average error: ' + str(average_error))\n",
    "        print('Std. error: ' + str(std_error))\n",
    "        all_errors.append(average_error)\n",
    "        all_std_devs.append(std_error)\n",
    "    print(all_errors)\n",
    "    print(all_std_devs)\n",
    "    print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need std dev for predicting all next years not just at 18 years old. So we modify this a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "start_age: 8\n",
      "------------------\n",
      "Data up to age: 9\n",
      "7569\n",
      "Predicting for 1 years ahead\n",
      "7568\n",
      "[ATV_diff_8-9       65.0\n",
      "ATV_diff_9-10      41.0\n",
      "ATV_diff_10-11     51.0\n",
      "ATV_diff_11-12     84.0\n",
      "ATV_diff_12-13     89.0\n",
      "ATV_diff_13-14    112.0\n",
      "ATV_diff_14-15     48.0\n",
      "ATV_diff_15-16     45.0\n",
      "ATV_diff_16-17     20.0\n",
      "ATV_diff_17-18      0.0\n",
      "Name: 3256, dtype: float64, ATV_diff_8-9      65.0\n",
      "ATV_diff_9-10     50.0\n",
      "ATV_diff_10-11    54.0\n",
      "ATV_diff_11-12    26.0\n",
      "ATV_diff_12-13    74.0\n",
      "ATV_diff_13-14    75.0\n",
      "ATV_diff_14-15    55.0\n",
      "ATV_diff_15-16    36.0\n",
      "ATV_diff_16-17   -10.0\n",
      "ATV_diff_17-18    21.0\n",
      "Name: 688, dtype: float64, ATV_diff_8-9      65.000000\n",
      "ATV_diff_9-10     62.500000\n",
      "ATV_diff_10-11    37.500000\n",
      "ATV_diff_11-12    64.583333\n",
      "ATV_diff_12-13    60.083333\n",
      "ATV_diff_13-14    56.666667\n",
      "ATV_diff_14-15     9.083333\n",
      "ATV_diff_15-16    11.000000\n",
      "ATV_diff_16-17    20.833333\n",
      "ATV_diff_17-18     7.333333\n",
      "Name: 5690, dtype: float64]\n",
      "-------------------\n",
      "1395.0\n",
      "1450.9788636363637\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [46], line 81\u001b[0m\n\u001b[0;32m     79\u001b[0m predicted_value \u001b[38;5;241m=\u001b[39m current_value \u001b[38;5;241m+\u001b[39m all_next_differences\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_value)\n\u001b[1;32m---> 81\u001b[0m z\u001b[38;5;241m=\u001b[39m\u001b[43mz\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m#actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[-1]]\u001b[39;00m\n\u001b[0;32m     83\u001b[0m actual_value \u001b[38;5;241m=\u001b[39m df_mens_atv\u001b[38;5;241m.\u001b[39miloc[i][df_mens_atv\u001b[38;5;241m.\u001b[39mcolumns[col_index_for_start_age \u001b[38;5;241m+\u001b[39m col_index_for_age \u001b[38;5;241m+\u001b[39m remaining_ages_for_difference]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "#Height men\n",
    "number_of_similar_rows_to_include_for_predictions = 100\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,9): #Predpostavimo da imamo vsa leta za nazaj, ker razlike niso tako velike\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "    #print(df_grad)\n",
    "    all_errors=[]\n",
    "    all_std_errors = []\n",
    "    \n",
    "    # for age in range(start_age,18):\n",
    "    for age in range(9,18):\n",
    "        print('Data up to age: ' + str(age))\n",
    "        col_index_for_age = age-start_age # start_age = 8\n",
    "        \n",
    "        #remaining_ages_for_difference = 18-age\n",
    "        \n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        similarity = scipy.spatial.distance.cdist(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "        print(len(similarity))\n",
    "        \n",
    "        predicting_errors =[]\n",
    "        all_errors=[]\n",
    "        all_std_errors = []\n",
    "        for remaining_ages_for_difference in range(1, 18-age+1): #, 18-age+1):\n",
    "        #for remaining_ages_for_difference in range(1, 2): #, 18-age+1):\n",
    "            print(f'Predicting for {remaining_ages_for_difference} years ahead')\n",
    "            predicting_errors =[]\n",
    "            #We iterate through rows\\\n",
    "            for i in range(len(similarity)):            \n",
    "                row = similarity[i]\n",
    "                #print(df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age]])\n",
    "                #print(df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]])\n",
    "                sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "                \n",
    "                del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "                print(len(sorted_indexes))\n",
    "                \n",
    "                #We get rows with simmilar differences\n",
    "                similar_rows = []\n",
    "                for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                    similar_rows.append(df_grad.iloc[sorted_indexes[j]]) #Original version                    \n",
    "\n",
    "                print(similar_rows[0:3])\n",
    "                print('-------------------')\n",
    "               \n",
    "                #Now we need to calculate remaining differences to estimate value at x\n",
    "                next_diferences = [0]*remaining_ages_for_difference\n",
    "                #print(next_diferences)\n",
    "                #z=z\n",
    "                #print()\n",
    "                for similar_row in similar_rows:\n",
    "                    for k in range(1, remaining_ages_for_difference+1):\n",
    "                        #print('k')\n",
    "                        #print(col_index_for_start_age + col_index_for_age)\n",
    "                        #print(k-1)\n",
    "                        #print(similar_row[k-1])\n",
    "                        #next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                        next_diferences[k-1] = next_diferences[k-1] + similar_row[col_index_for_start_age + col_index_for_age + k-1] #we add difference from simmilar rows for each year\n",
    "                        #next_diferences[k] = next_diferences[k] + similar_row[k]\n",
    "                        #print(f'Similar row value: {similar_row[k]}')\n",
    "                \n",
    "                next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "                \n",
    "                #print('next')\n",
    "                #print(next_diferences)\n",
    "                #break\n",
    "                all_next_differences = sum(next_diferences)\n",
    "                \n",
    "                current_value = 1395.0\n",
    "                print(current_value)\n",
    "                \n",
    "                predicted_value = current_value + all_next_differences\n",
    "                print(predicted_value)\n",
    "                \n",
    "                #actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[-1]]\n",
    "                actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]]\n",
    "                #print(actual_value)\n",
    "                z=z\n",
    "                predicting_error = abs(predicted_value - actual_value)\n",
    "                predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "            #Average predicting error\n",
    "            predicting_errors = [x for x in predicting_errors if x < 150]\n",
    "            average_error = np.median(predicting_errors)\n",
    "            std_error = np.std(predicting_errors)\n",
    "            print('Average error: ' + str(average_error))\n",
    "            #print(predicting_errors)\n",
    "            print('Std. error: ' + str(std_error))\n",
    "            all_errors.append(average_error)\n",
    "            all_std_errors.append(std_error)\n",
    "        print(all_errors)\n",
    "        print(all_std_errors)\n",
    "        print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Height women\n",
    "number_of_similar_rows_to_include_for_predictions = 100\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,9): #Predpostavimo da imamo vsa leta za nazaj, ker razlike niso tako velike\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_errors = []\n",
    "    for age in range(start_age,18):\n",
    "        print('Data up to age: ' + str(age))\n",
    "        col_index_for_age = age-start_age # start_age = 8\n",
    "        \n",
    "        #remaining_ages_for_difference = 18-age\n",
    "        \n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        similarity = scipy.spatial.distance.cdist(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "\n",
    "        predicting_errors =[]\n",
    "        all_errors=[]\n",
    "        all_std_errors = []\n",
    "        for remaining_ages_for_difference in range(1, 18-age+1): #, 18-age+1):\n",
    "        #for remaining_ages_for_difference in range(1, 2): #, 18-age+1):\n",
    "            print(f'Predicting for {remaining_ages_for_difference} years ahead')\n",
    "            predicting_errors =[]\n",
    "            #We iterate through rows\n",
    "            for i in range(len(similarity)):            \n",
    "                row = similarity[i]\n",
    "                #print(df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age]])\n",
    "                #print(df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]])\n",
    "                sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "                del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "                #We get rows with simmilar differences\n",
    "                similar_rows = []\n",
    "                for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                    similar_rows.append(df_grad.iloc[sorted_indexes[j]]) #Original version                    \n",
    "\n",
    "                #print(similar_rows[0:3])\n",
    "                #print('-------------------')\n",
    "                \n",
    "                #Now we need to calculate remaining differences to estimate value at x\n",
    "                next_diferences = [0]*remaining_ages_for_difference\n",
    "                #print(similar_rows[-1])\n",
    "                #print()\n",
    "                for similar_row in similar_rows:\n",
    "                    for k in range(1, remaining_ages_for_difference+1):\n",
    "                        #print('k')\n",
    "                        #print(col_index_for_start_age + col_index_for_age)\n",
    "                        #print(k-1)\n",
    "                        #print(similar_row[k-1])\n",
    "                        #next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                        next_diferences[k-1] = next_diferences[k-1] + similar_row[col_index_for_start_age + col_index_for_age + k-1] #we add difference from simmilar rows for each year\n",
    "                        #next_diferences[k] = next_diferences[k] + similar_row[k]\n",
    "                        #print(f'Similar row value: {similar_row[k]}')\n",
    "                next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "                #print('next')\n",
    "                #print(next_diferences)\n",
    "                #break\n",
    "                all_next_differences = sum(next_diferences)\n",
    "                current_value = df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age]]\n",
    "\n",
    "                predicted_value = current_value + all_next_differences\n",
    "                #actual_value = df_womens_atv.iloc[i][df_womens_atv.columns[-1]]\n",
    "                actual_value = df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]]\n",
    "\n",
    "                predicting_error = abs(predicted_value - actual_value)\n",
    "                predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "            #Average predicting error\n",
    "            predicting_errors = [x for x in predicting_errors if x < 150]\n",
    "            average_error = np.median(predicting_errors)\n",
    "            std_error = np.std(predicting_errors)\n",
    "            print('Average error: ' + str(average_error))\n",
    "            #print(predicting_errors)\n",
    "            print('Std. error: ' + str(std_error))\n",
    "            all_errors.append(average_error)\n",
    "            all_std_errors.append(std_error)\n",
    "        print(all_errors)\n",
    "        print(all_std_errors)\n",
    "        print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
