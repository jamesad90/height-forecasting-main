{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Comparing methods for predicting height.ipynb', 'jd_bst.py', 'Similarity comparison (std. dev).ipynb', 'svk_600_60_dt_men_2018.csv', 'svk_600_60_dt_women_2018.csv', 'svk_height_weight_mens_2008_v2.csv', 'svk_height_weight_womens_2018_v2.csv', 'test.html']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import diff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from IPython.display import clear_output\n",
    "import scipy\n",
    "print(os.listdir())\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\AppData\\Local\\Temp\\ipykernel_27144\\4021082537.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/svk_height_weight_womens_2008_v2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\James\\OneDrive - Nottingham Trent University\\SHP\\height-forecasting-main\\src\\Similarity comparison (std. dev).ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_mens \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../data/svk_height_weight_mens_2008_v2.csv\u001b[39m\u001b[39m'\u001b[39m,sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_womens \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/svk_height_weight_womens_2008_v2.csv\u001b[39;49m\u001b[39m'\u001b[39;49m,sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\James\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/svk_height_weight_womens_2008_v2.csv'"
     ]
    }
   ],
   "source": [
    "df_mens = pd.read_csv('../data/svk_height_weight_mens_2008_v2.csv',sep=',', index_col=0).reset_index(drop=True)\n",
    "df_womens = pd.read_csv('../data/svk_height_weight_womens_2008_v2.csv',sep=',', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_id</th>\n",
       "      <th>ATV_8</th>\n",
       "      <th>ATV_9</th>\n",
       "      <th>ATV_10</th>\n",
       "      <th>ATV_11</th>\n",
       "      <th>ATV_12</th>\n",
       "      <th>ATV_13</th>\n",
       "      <th>ATV_14</th>\n",
       "      <th>ATV_15</th>\n",
       "      <th>ATV_16</th>\n",
       "      <th>ATV_17</th>\n",
       "      <th>ATV_18</th>\n",
       "      <th>ATT_8</th>\n",
       "      <th>ATT_9</th>\n",
       "      <th>ATT_10</th>\n",
       "      <th>ATT_11</th>\n",
       "      <th>ATT_12</th>\n",
       "      <th>ATT_13</th>\n",
       "      <th>ATT_14</th>\n",
       "      <th>ATT_15</th>\n",
       "      <th>ATT_16</th>\n",
       "      <th>ATT_17</th>\n",
       "      <th>ATT_18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>1000301911</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>1437.916667</td>\n",
       "      <td>1499.166667</td>\n",
       "      <td>1560.833333</td>\n",
       "      <td>1640.000000</td>\n",
       "      <td>1749.583333</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1865.000000</td>\n",
       "      <td>1867.083333</td>\n",
       "      <td>1874.166667</td>\n",
       "      <td>1886.250000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>341.25</td>\n",
       "      <td>375.00</td>\n",
       "      <td>430.833333</td>\n",
       "      <td>499.583333</td>\n",
       "      <td>602.916667</td>\n",
       "      <td>690.833333</td>\n",
       "      <td>740.833333</td>\n",
       "      <td>786.666667</td>\n",
       "      <td>818.333333</td>\n",
       "      <td>838.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>1000234385</td>\n",
       "      <td>1344.166667</td>\n",
       "      <td>1395.833333</td>\n",
       "      <td>1439.416667</td>\n",
       "      <td>1499.833333</td>\n",
       "      <td>1537.083333</td>\n",
       "      <td>1604.166667</td>\n",
       "      <td>1707.166667</td>\n",
       "      <td>1756.333333</td>\n",
       "      <td>1805.833333</td>\n",
       "      <td>1814.583333</td>\n",
       "      <td>1824.166667</td>\n",
       "      <td>296.666667</td>\n",
       "      <td>355.00</td>\n",
       "      <td>401.25</td>\n",
       "      <td>414.166667</td>\n",
       "      <td>433.333333</td>\n",
       "      <td>501.916667</td>\n",
       "      <td>580.416667</td>\n",
       "      <td>676.833333</td>\n",
       "      <td>717.083333</td>\n",
       "      <td>765.833333</td>\n",
       "      <td>796.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        child_id        ATV_8        ATV_9       ATV_10       ATV_11  \\\n",
       "6478  1000301911  1380.000000  1437.916667  1499.166667  1560.833333   \n",
       "3138  1000234385  1344.166667  1395.833333  1439.416667  1499.833333   \n",
       "\n",
       "           ATV_12       ATV_13       ATV_14       ATV_15       ATV_16  \\\n",
       "6478  1640.000000  1749.583333  1830.000000  1865.000000  1867.083333   \n",
       "3138  1537.083333  1604.166667  1707.166667  1756.333333  1805.833333   \n",
       "\n",
       "           ATV_17       ATV_18       ATT_8   ATT_9  ATT_10      ATT_11  \\\n",
       "6478  1874.166667  1886.250000  335.000000  341.25  375.00  430.833333   \n",
       "3138  1814.583333  1824.166667  296.666667  355.00  401.25  414.166667   \n",
       "\n",
       "          ATT_12      ATT_13      ATT_14      ATT_15      ATT_16      ATT_17  \\\n",
       "6478  499.583333  602.916667  690.833333  740.833333  786.666667  818.333333   \n",
       "3138  433.333333  501.916667  580.416667  676.833333  717.083333  765.833333   \n",
       "\n",
       "          ATT_18  \n",
       "6478  838.333333  \n",
       "3138  796.583333  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mens.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7577"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_mens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9181"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_womens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "atv_column_names = [x for x in df_mens.columns if 'ATV' in x]\n",
    "df_mens_atv = df_mens[atv_column_names]\n",
    "atv_column_names = [x for x in df_womens.columns if 'ATV' in x]\n",
    "df_womens_atv = df_womens[atv_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mens_atv = df_mens_atv[(df_mens_atv != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_womens_atv = df_womens_atv[(df_womens_atv != 0).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_column_names = [x for x in df_mens.columns if 'ATT' in x]\n",
    "df_mens_att = df_mens[att_column_names]\n",
    "att_column_names = [x for x in df_womens.columns if 'ATT' in x]\n",
    "df_womens_att = df_womens[att_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mens_600m = pd.read_csv('../data/svk_600_60_dt_men_2018.csv',sep=',', index_col=0).reset_index(drop=True)\n",
    "df_womens_600m = pd.read_csv('../data/svk_600_60_dt_women_2018.csv',sep=',', index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "att600_column_names = [x for x in df_mens_600m.columns if 'T600' in x]\n",
    "df_mens_att600 = df_mens_600m[att600_column_names]\n",
    "att600_column_names = [x for x in df_womens_600m.columns if 'T600' in x]\n",
    "df_womens_att600 = df_womens_600m[att600_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mens_600m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\James\\OneDrive - Nottingham Trent University\\SHP\\height-forecasting-main\\src\\Similarity comparison (std. dev).ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m atdt_column_names \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df_mens_600m\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mDT\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m x] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_mens_atv \u001b[39m=\u001b[39m df_mens_600m[atdt_column_names]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m atdt_column_names \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m df_womens_600m\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mDT\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m x]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mens_600m' is not defined"
     ]
    }
   ],
   "source": [
    "atdt_column_names = [x for x in df_mens_600m.columns if 'DT' in x] \n",
    "df_mens_atv = df_mens_600m[atdt_column_names]\n",
    "atdt_column_names = [x for x in df_womens_600m.columns if 'DT' in x]\n",
    "df_womens_atdt = df_womens_600m[atdt_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_mens_atv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\James\\OneDrive - Nottingham Trent University\\SHP\\height-forecasting-main\\src\\Similarity comparison (std. dev).ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/James/OneDrive%20-%20Nottingham%20Trent%20University/SHP/height-forecasting-main/src/Similarity%20comparison%20%28std.%20dev%29.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(df_mens_atv)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_mens_atv' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_mens_atv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because we calculate difefrences between years, we need to name the columns right, so we prepare the names here\n",
    "atv_column_names_gradient = []\n",
    "for i in range(8, 18):\n",
    "    atv_column_names_gradient.append('ATV_diff_'+str(i)+'-'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "start_age: 8\n",
      "------------------\n",
      "Average error: 6.2399999999999665\n",
      "Std. error: 5.738211122556062\n",
      "Average error: 6.060833333333427\n",
      "Std. error: 5.723724670515744\n",
      "Average error: 5.819166666666668\n",
      "Std. error: 5.698747223202996\n",
      "Average error: 5.846666666666621\n",
      "Std. error: 5.4584373076450845\n",
      "Average error: 5.723333333333429\n",
      "Std. error: 5.434673128362942\n",
      "Average error: 5.4316666666667075\n",
      "Std. error: 5.335349621157837\n",
      "Average error: 5.31916666666671\n",
      "Std. error: 5.358354151236677\n",
      "Average error: 5.138333333333335\n",
      "Std. error: 5.287664392481464\n",
      "Average error: 4.654166666666647\n",
      "Std. error: 4.967100393146613\n",
      "Average error: 3.4633333333334377\n",
      "Std. error: 4.194219797860213\n",
      "[6.2399999999999665, 6.060833333333427, 5.819166666666668, 5.846666666666621, 5.723333333333429, 5.4316666666667075, 5.31916666666671, 5.138333333333335, 4.654166666666647, 3.4633333333334377]\n",
      "[5.738211122556062, 5.723724670515744, 5.698747223202996, 5.4584373076450845, 5.434673128362942, 5.335349621157837, 5.358354151236677, 5.287664392481464, 4.967100393146613, 4.194219797860213]\n",
      "Sum errors: 53.69666666666695\n",
      "------------------\n",
      "start_age: 9\n",
      "------------------\n",
      "Average error: 6.168333333333294\n",
      "Std. error: 5.741456199137551\n",
      "Average error: 5.892499999999977\n",
      "Std. error: 5.686287905234039\n",
      "Average error: 5.770833333333314\n",
      "Std. error: 5.4597390959286916\n",
      "Average error: 5.661666666666669\n",
      "Std. error: 5.405246490577035\n",
      "Average error: 5.489999999999981\n",
      "Std. error: 5.334832940544854\n",
      "Average error: 5.224166666666662\n",
      "Std. error: 5.326026643612614\n",
      "Average error: 5.116666666666681\n",
      "Std. error: 5.263450356171632\n",
      "Average error: 4.533333333333324\n",
      "Std. error: 4.940238807853197\n",
      "Average error: 3.4666666666667183\n",
      "Std. error: 4.19682259291852\n",
      "[6.168333333333294, 5.892499999999977, 5.770833333333314, 5.661666666666669, 5.489999999999981, 5.224166666666662, 5.116666666666681, 4.533333333333324, 3.4666666666667183]\n",
      "[5.741456199137551, 5.686287905234039, 5.4597390959286916, 5.405246490577035, 5.334832940544854, 5.326026643612614, 5.263450356171632, 4.940238807853197, 4.19682259291852]\n",
      "Sum errors: 47.32416666666662\n",
      "------------------\n",
      "start_age: 10\n",
      "------------------\n",
      "Average error: 6.07999999999992\n",
      "Std. error: 5.622306786222855\n",
      "Average error: 5.745000000000033\n",
      "Std. error: 5.464827399104668\n",
      "Average error: 5.678333333333356\n",
      "Std. error: 5.3920881986229166\n",
      "Average error: 5.423333333333389\n",
      "Std. error: 5.316253760533932\n",
      "Average error: 5.258333333333319\n",
      "Std. error: 5.294829999734214\n",
      "Average error: 5.14500000000006\n",
      "Std. error: 5.263382390387798\n",
      "Average error: 4.573333333333231\n",
      "Std. error: 4.933266807100326\n",
      "Average error: 3.464166666666671\n",
      "Std. error: 4.194471279785336\n",
      "[6.07999999999992, 5.745000000000033, 5.678333333333356, 5.423333333333389, 5.258333333333319, 5.14500000000006, 4.573333333333231, 3.464166666666671]\n",
      "[5.622306786222855, 5.464827399104668, 5.3920881986229166, 5.316253760533932, 5.294829999734214, 5.263382390387798, 4.933266807100326, 4.194471279785336]\n",
      "Sum errors: 41.36749999999998\n",
      "------------------\n",
      "start_age: 11\n",
      "------------------\n",
      "Average error: 5.804999999999971\n",
      "Std. error: 5.41798015737723\n",
      "Average error: 5.650000000000034\n",
      "Std. error: 5.3708128278274785\n",
      "Average error: 5.43916666666685\n",
      "Std. error: 5.292490965045048\n",
      "Average error: 5.2366666666666575\n",
      "Std. error: 5.242338722078151\n",
      "Average error: 5.178333333333349\n",
      "Std. error: 5.226406757493161\n",
      "Average error: 4.535000000000032\n",
      "Std. error: 4.89390717271675\n",
      "Average error: 3.4199999999999235\n",
      "Std. error: 4.199395270837466\n",
      "[5.804999999999971, 5.650000000000034, 5.43916666666685, 5.2366666666666575, 5.178333333333349, 4.535000000000032, 3.4199999999999235]\n",
      "[5.41798015737723, 5.3708128278274785, 5.292490965045048, 5.242338722078151, 5.226406757493161, 4.89390717271675, 4.199395270837466]\n",
      "Sum errors: 35.26416666666682\n",
      "------------------\n",
      "start_age: 12\n",
      "------------------\n",
      "Average error: 5.645833333333314\n",
      "Std. error: 5.3636258983643375\n",
      "Average error: 5.434999999999981\n",
      "Std. error: 5.281676768368356\n",
      "Average error: 5.221666666666756\n",
      "Std. error: 5.229674744189633\n",
      "Average error: 5.155833333333504\n",
      "Std. error: 5.1850695637152375\n",
      "Average error: 4.513333333333293\n",
      "Std. error: 4.887809781471566\n",
      "Average error: 3.3624999999999687\n",
      "Std. error: 4.181594796584869\n",
      "[5.645833333333314, 5.434999999999981, 5.221666666666756, 5.155833333333504, 4.513333333333293, 3.3624999999999687]\n",
      "[5.3636258983643375, 5.281676768368356, 5.229674744189633, 5.1850695637152375, 4.887809781471566, 4.181594796584869]\n",
      "Sum errors: 29.334166666666817\n",
      "------------------\n",
      "start_age: 13\n",
      "------------------\n",
      "Average error: 5.506666666666774\n",
      "Std. error: 5.217479670840506\n",
      "Average error: 5.197499999999984\n",
      "Std. error: 5.195789131816624\n",
      "Average error: 5.1975000000000335\n",
      "Std. error: 5.171723382648913\n",
      "Average error: 4.534999999999911\n",
      "Std. error: 4.853491033794738\n",
      "Average error: 3.3775000000001043\n",
      "Std. error: 4.175495004454073\n",
      "[5.506666666666774, 5.197499999999984, 5.1975000000000335, 4.534999999999911, 3.3775000000001043]\n",
      "[5.217479670840506, 5.195789131816624, 5.171723382648913, 4.853491033794738, 4.175495004454073]\n",
      "Sum errors: 23.814166666666807\n",
      "------------------\n",
      "start_age: 14\n",
      "------------------\n",
      "Average error: 5.213333333333296\n",
      "Std. error: 5.187765642396995\n",
      "Average error: 5.251666666666637\n",
      "Std. error: 5.189610404638067\n",
      "Average error: 4.463333333333466\n",
      "Std. error: 4.838278725000059\n",
      "Average error: 3.346666666666657\n",
      "Std. error: 4.181112785030529\n",
      "[5.213333333333296, 5.251666666666637, 4.463333333333466, 3.346666666666657]\n",
      "[5.187765642396995, 5.189610404638067, 4.838278725000059, 4.181112785030529]\n",
      "Sum errors: 18.275000000000055\n",
      "------------------\n",
      "start_age: 15\n",
      "------------------\n",
      "Average error: 5.250000000000014\n",
      "Std. error: 5.179694602874984\n",
      "Average error: 4.553333333333271\n",
      "Std. error: 4.835028648914114\n",
      "Average error: 3.394166666666493\n",
      "Std. error: 4.149352487614796\n",
      "[5.250000000000014, 4.553333333333271, 3.394166666666493]\n",
      "[5.179694602874984, 4.835028648914114, 4.149352487614796]\n",
      "Sum errors: 13.197499999999778\n",
      "------------------\n",
      "start_age: 16\n",
      "------------------\n",
      "Average error: 4.619999999999983\n",
      "Std. error: 4.825843094424223\n",
      "Average error: 3.394166666666621\n",
      "Std. error: 4.158172476733166\n",
      "[4.619999999999983, 3.394166666666621]\n",
      "[4.825843094424223, 4.158172476733166]\n",
      "Sum errors: 8.014166666666604\n",
      "------------------\n",
      "start_age: 17\n",
      "------------------\n",
      "Average error: 3.4666666666666686\n",
      "Std. error: 4.147226494809696\n",
      "[3.4666666666666686]\n",
      "[4.147226494809696]\n",
      "Sum errors: 3.4666666666666686\n"
     ]
    }
   ],
   "source": [
    "#Height men\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,18):\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_devs=[]\n",
    "    for age in range(start_age,18):\n",
    "        #print(age)\n",
    "        col_index_for_age = age-start_age #first year = 8\n",
    "        remaining_ages_for_difference = 18-age\n",
    "        number_of_similar_rows_to_include_for_predictions = 100\n",
    "        predicting_errors =[]\n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        #print(col_index_for_start_age)\n",
    "        #print(col_index_for_age)\n",
    "        #similarity = cosine_similarity(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]])\n",
    "        similarity = scipy.spatial.distance.cdist(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "\n",
    "        #We iterate through rows\n",
    "        for i in range(len(similarity)):\n",
    "            row = similarity[i]\n",
    "            sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "            del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "            #We get rows with simmilar differences\n",
    "            similar_rows = []\n",
    "            for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                similar_rows.append(df_grad.iloc[sorted_indexes[j]])\n",
    "\n",
    "            #Now we need to calculate remaining differences to estimate value at 18\n",
    "            next_diferences = [0]*remaining_ages_for_difference\n",
    "            #print(similar_rows[-1])\n",
    "            #print()\n",
    "            for similar_row in similar_rows:\n",
    "                for k in range(remaining_ages_for_difference):\n",
    "                    next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                    #print(similar_row[-k-1])\n",
    "            next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "            all_next_differences = sum(next_diferences)\n",
    "            current_value = df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age]]\n",
    "\n",
    "            predicted_value = current_value + all_next_differences\n",
    "            actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[-1]]\n",
    "\n",
    "            predicting_error = abs(predicted_value - actual_value)\n",
    "            predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "        #Average predicting error\n",
    "        average_error = np.median(predicting_errors)\n",
    "        std_error = np.std(predicting_errors)\n",
    "        print('Average error: ' + str(average_error))\n",
    "        print('Std. error: ' + str(std_error))\n",
    "        all_errors.append(average_error)\n",
    "        all_std_devs.append(std_error)\n",
    "    print(all_errors)\n",
    "    print(all_std_devs)\n",
    "    print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "start_age: 8\n",
      "------------------\n",
      "Average error: 28.506666666666547\n",
      "Std. error: 43.90840195066897\n",
      "Average error: 27.584423076922803\n",
      "Std. error: 42.76557982865211\n",
      "Average error: 27.640454545454418\n",
      "Std. error: 34.711706140431644\n",
      "Average error: 27.14125000000047\n",
      "Std. error: 28.576320892267656\n",
      "Average error: 24.61000000000024\n",
      "Std. error: 27.998268727597754\n",
      "Average error: 16.886474358973942\n",
      "Std. error: 24.66863904342307\n",
      "Average error: 11.291856060606165\n",
      "Std. error: 19.04990974534392\n",
      "Average error: 8.403216783216067\n",
      "Std. error: 16.157570759944182\n",
      "Average error: 6.3865093240087845\n",
      "Std. error: 16.996213501820908\n",
      "Average error: 3.9127243589738328\n",
      "Std. error: 11.396631018710098\n",
      "[28.506666666666547, 27.584423076922803, 27.640454545454418, 27.14125000000047, 24.61000000000024, 16.886474358973942, 11.291856060606165, 8.403216783216067, 6.3865093240087845, 3.9127243589738328]\n",
      "[43.90840195066897, 42.76557982865211, 34.711706140431644, 28.576320892267656, 27.998268727597754, 24.66863904342307, 19.04990974534392, 16.157570759944182, 16.996213501820908, 11.396631018710098]\n",
      "Sum errors: 182.36357517482327\n",
      "------------------\n",
      "start_age: 9\n",
      "------------------\n",
      "Average error: 28.185352564102914\n",
      "Std. error: 42.62324170927876\n",
      "Average error: 27.47331876456849\n",
      "Std. error: 34.84401454726436\n",
      "Average error: 27.292674825175595\n",
      "Std. error: 28.671370129639012\n",
      "Average error: 24.72177738927735\n",
      "Std. error: 28.10158728098731\n",
      "Average error: 16.62614801864936\n",
      "Std. error: 24.691075514081767\n",
      "Average error: 11.15826923076952\n",
      "Std. error: 18.966040543143666\n",
      "Average error: 8.409417249417515\n",
      "Std. error: 16.125776298039174\n",
      "Average error: 6.380192307691686\n",
      "Std. error: 16.966030179870447\n",
      "Average error: 3.869032634031896\n",
      "Std. error: 11.391783971525822\n",
      "[28.185352564102914, 27.47331876456849, 27.292674825175595, 24.72177738927735, 16.62614801864936, 11.15826923076952, 8.409417249417515, 6.380192307691686, 3.869032634031896]\n",
      "[42.62324170927876, 34.84401454726436, 28.671370129639012, 28.10158728098731, 24.691075514081767, 18.966040543143666, 16.125776298039174, 16.966030179870447, 11.391783971525822]\n",
      "Sum errors: 154.11618298368433\n",
      "------------------\n",
      "start_age: 10\n",
      "------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(similarity)):\n\u001b[1;32m     29\u001b[0m     row \u001b[38;5;241m=\u001b[39m similarity[i]\n\u001b[0;32m---> 30\u001b[0m     sorted_indexes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m#We sort values from biggest similarity to lowest-we get indexes of those values\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m sorted_indexes[sorted_indexes\u001b[38;5;241m.\u001b[39mindex(i)] \u001b[38;5;66;03m#Remove value of index of the same value to remove similati of the same values\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#We get rows with simmilar differences\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1114\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \n\u001b[1;32m   1113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Height women\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,18):\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_devs=[]\n",
    "    for age in range(start_age,18):\n",
    "        #print(age)\n",
    "        col_index_for_age = age-start_age #first year = 8\n",
    "        remaining_ages_for_difference = 18-age\n",
    "        number_of_similar_rows_to_include_for_predictions = 100\n",
    "        predicting_errors =[]\n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        #print(col_index_for_start_age)\n",
    "        #print(col_index_for_age)\n",
    "        #similarity = cosine_similarity(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]])\n",
    "        similarity = scipy.spatial.distance.cdist(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "\n",
    "        #We iterate through rows\n",
    "        for i in range(len(similarity)):\n",
    "            row = similarity[i]\n",
    "            sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "            del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "            #We get rows with simmilar differences\n",
    "            similar_rows = []\n",
    "            for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                similar_rows.append(df_grad.iloc[sorted_indexes[j]])\n",
    "\n",
    "            #Now we need to calculate remaining differences to estimate value at 18\n",
    "            next_diferences = [0]*remaining_ages_for_difference\n",
    "            #print(similar_rows[-1])\n",
    "            #print()\n",
    "            for similar_row in similar_rows:\n",
    "                for k in range(remaining_ages_for_difference):\n",
    "                    next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                    #print(similar_row[-k-1])\n",
    "            next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "            all_next_differences = sum(next_diferences)\n",
    "            current_value = df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age]]\n",
    "\n",
    "            predicted_value = current_value + all_next_differences\n",
    "            actual_value = df_womens_atv.iloc[i][df_womens_atv.columns[-1]]\n",
    "\n",
    "            predicting_error = abs(predicted_value - actual_value)\n",
    "            predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "        #Average predicting error\n",
    "        average_error = np.median(predicting_errors)\n",
    "        std_error = np.std(predicting_errors)\n",
    "        print('Average error: ' + str(average_error))\n",
    "        print('Std. error: ' + str(std_error))\n",
    "        all_errors.append(average_error)\n",
    "        all_std_devs.append(std_error)\n",
    "    print(all_errors)\n",
    "    print(all_std_devs)\n",
    "    print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need std dev for predicting all next years not just at 18 years old. So we modify this a bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Height men\n",
    "number_of_similar_rows_to_include_for_predictions = 100\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,9): #Predpostavimo da imamo vsa leta za nazaj, ker razlike niso tako velike\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_errors = []\n",
    "    for age in range(start_age,18):\n",
    "        print('Data up to age: ' + str(age))\n",
    "        col_index_for_age = age-start_age # start_age = 8\n",
    "        \n",
    "        #remaining_ages_for_difference = 18-age\n",
    "        \n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        similarity = scipy.spatial.distance.cdist(df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_mens_atv[df_mens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "\n",
    "        predicting_errors =[]\n",
    "        all_errors=[]\n",
    "        all_std_errors = []\n",
    "        for remaining_ages_for_difference in range(1, 18-age+1): #, 18-age+1):\n",
    "        #for remaining_ages_for_difference in range(1, 2): #, 18-age+1):\n",
    "            print(f'Predicting for {remaining_ages_for_difference} years ahead')\n",
    "            predicting_errors =[]\n",
    "            #We iterate through rows\n",
    "            for i in range(len(similarity)):            \n",
    "                row = similarity[i]\n",
    "                #print(df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age]])\n",
    "                #print(df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]])\n",
    "                sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "                del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "                #We get rows with simmilar differences\n",
    "                similar_rows = []\n",
    "                for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                    similar_rows.append(df_grad.iloc[sorted_indexes[j]]) #Original version                    \n",
    "\n",
    "                #print(similar_rows[0:3])\n",
    "                #print('-------------------')\n",
    "                \n",
    "                #Now we need to calculate remaining differences to estimate value at x\n",
    "                next_diferences = [0]*remaining_ages_for_difference\n",
    "                #print(similar_rows[-1])\n",
    "                #print()\n",
    "                for similar_row in similar_rows:\n",
    "                    for k in range(1, remaining_ages_for_difference+1):\n",
    "                        #print('k')\n",
    "                        #print(col_index_for_start_age + col_index_for_age)\n",
    "                        #print(k-1)\n",
    "                        #print(similar_row[k-1])\n",
    "                        #next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                        next_diferences[k-1] = next_diferences[k-1] + similar_row[col_index_for_start_age + col_index_for_age + k-1] #we add difference from simmilar rows for each year\n",
    "                        #next_diferences[k] = next_diferences[k] + similar_row[k]\n",
    "                        #print(f'Similar row value: {similar_row[k]}')\n",
    "                next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "                #print('next')\n",
    "                #print(next_diferences)\n",
    "                #break\n",
    "                all_next_differences = sum(next_diferences)\n",
    "                current_value = df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age]]\n",
    "\n",
    "                predicted_value = current_value + all_next_differences\n",
    "                #actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[-1]]\n",
    "                actual_value = df_mens_atv.iloc[i][df_mens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]]\n",
    "\n",
    "                predicting_error = abs(predicted_value - actual_value)\n",
    "                predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "            #Average predicting error\n",
    "            predicting_errors = [x for x in predicting_errors if x < 150]\n",
    "            average_error = np.median(predicting_errors)\n",
    "            std_error = np.std(predicting_errors)\n",
    "            print('Average error: ' + str(average_error))\n",
    "            #print(predicting_errors)\n",
    "            print('Std. error: ' + str(std_error))\n",
    "            all_errors.append(average_error)\n",
    "            all_std_errors.append(std_error)\n",
    "        print(all_errors)\n",
    "        print(all_std_errors)\n",
    "        print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Height women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Height women\n",
    "number_of_similar_rows_to_include_for_predictions = 100\n",
    "all_all_errors=[]\n",
    "for start_age in range(8,9): #Predpostavimo da imamo vsa leta za nazaj, ker razlike niso tako velike\n",
    "    print('------------------')\n",
    "    print('start_age: ' + str(start_age))\n",
    "    print('------------------')\n",
    "    col_index_for_start_age = start_age-8 #first year = 8\n",
    "    diffs = diff(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:]].values)\n",
    "    atv_column_names_gradient_current = atv_column_names_gradient[col_index_for_start_age:]\n",
    "    df_grad = pd.DataFrame(data=diffs, columns=atv_column_names_gradient_current)\n",
    "\n",
    "    all_errors=[]\n",
    "    all_std_errors = []\n",
    "    for age in range(start_age,18):\n",
    "        print('Data up to age: ' + str(age))\n",
    "        col_index_for_age = age-start_age # start_age = 8\n",
    "        \n",
    "        #remaining_ages_for_difference = 18-age\n",
    "        \n",
    "        #Calculate similarities between year differences\n",
    "        #Simialrities are calculated only for values lower than age\n",
    "        similarity = scipy.spatial.distance.cdist(df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], df_womens_atv[df_womens_atv.columns[col_index_for_start_age:col_index_for_start_age + col_index_for_age+1]], metric='euclidean')\n",
    "\n",
    "        predicting_errors =[]\n",
    "        all_errors=[]\n",
    "        all_std_errors = []\n",
    "        for remaining_ages_for_difference in range(1, 18-age+1): #, 18-age+1):\n",
    "        #for remaining_ages_for_difference in range(1, 2): #, 18-age+1):\n",
    "            print(f'Predicting for {remaining_ages_for_difference} years ahead')\n",
    "            predicting_errors =[]\n",
    "            #We iterate through rows\n",
    "            for i in range(len(similarity)):            \n",
    "                row = similarity[i]\n",
    "                #print(df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age]])\n",
    "                #print(df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]])\n",
    "                sorted_indexes = list(np.argsort(row)) #We sort values from biggest similarity to lowest-we get indexes of those values\n",
    "                del sorted_indexes[sorted_indexes.index(i)] #Remove value of index of the same value to remove similati of the same values\n",
    "\n",
    "                #We get rows with simmilar differences\n",
    "                similar_rows = []\n",
    "                for j in range(number_of_similar_rows_to_include_for_predictions):\n",
    "                    similar_rows.append(df_grad.iloc[sorted_indexes[j]]) #Original version                    \n",
    "\n",
    "                #print(similar_rows[0:3])\n",
    "                #print('-------------------')\n",
    "                \n",
    "                #Now we need to calculate remaining differences to estimate value at x\n",
    "                next_diferences = [0]*remaining_ages_for_difference\n",
    "                #print(similar_rows[-1])\n",
    "                #print()\n",
    "                for similar_row in similar_rows:\n",
    "                    for k in range(1, remaining_ages_for_difference+1):\n",
    "                        #print('k')\n",
    "                        #print(col_index_for_start_age + col_index_for_age)\n",
    "                        #print(k-1)\n",
    "                        #print(similar_row[k-1])\n",
    "                        #next_diferences[-k-1] = next_diferences[-k-1] + similar_row[-k-1] #we add difference from simmilar rows for each year\n",
    "                        next_diferences[k-1] = next_diferences[k-1] + similar_row[col_index_for_start_age + col_index_for_age + k-1] #we add difference from simmilar rows for each year\n",
    "                        #next_diferences[k] = next_diferences[k] + similar_row[k]\n",
    "                        #print(f'Similar row value: {similar_row[k]}')\n",
    "                next_diferences = np.array(next_diferences)/number_of_similar_rows_to_include_for_predictions #divide to get average\n",
    "                #print('next')\n",
    "                #print(next_diferences)\n",
    "                #break\n",
    "                all_next_differences = sum(next_diferences)\n",
    "                current_value = df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age]]\n",
    "\n",
    "                predicted_value = current_value + all_next_differences\n",
    "                #actual_value = df_womens_atv.iloc[i][df_womens_atv.columns[-1]]\n",
    "                actual_value = df_womens_atv.iloc[i][df_womens_atv.columns[col_index_for_start_age + col_index_for_age + remaining_ages_for_difference]]\n",
    "\n",
    "                predicting_error = abs(predicted_value - actual_value)\n",
    "                predicting_errors.append(predicting_error)\n",
    "\n",
    "\n",
    "            #Average predicting error\n",
    "            predicting_errors = [x for x in predicting_errors if x < 150]\n",
    "            average_error = np.median(predicting_errors)\n",
    "            std_error = np.std(predicting_errors)\n",
    "            print('Average error: ' + str(average_error))\n",
    "            #print(predicting_errors)\n",
    "            print('Std. error: ' + str(std_error))\n",
    "            all_errors.append(average_error)\n",
    "            all_std_errors.append(std_error)\n",
    "        print(all_errors)\n",
    "        print(all_std_errors)\n",
    "        print('Sum errors: ' + str(sum(all_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
